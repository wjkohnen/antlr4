fileHeader(grammarFileName, ANTLRVersion) ::= <<
// Generated from <grammarFileName; format="java-escape"> by ANTLR <ANTLRVersion>.

>>

ParserFile(file, parser, namedActions) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage> // <file.grammarName>
<else>
package parser // <file.grammarName>
<endif>

import (
    "reflect"
    "fmt"
    "strconv"

    "github.com/pboyer/antlr4/runtime/Go/antlr"
)

// Stopgap to suppress unused import error. We aren't certain
// to have these imports used in the generated code below

var _ = fmt.Printf
var _ = reflect.Copy
var _ = strconv.Itoa

<namedActions.header>

<parser>

>>

ListenerFile(file, header) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage> // <file.grammarName>
<else>
package parser // <file.grammarName>
<endif>

import "github.com/pboyer/antlr4/runtime/Go/antlr"

// A complete listener for a parse tree produced by <file.parserName>

type <file.grammarName>Listener interface {
    antlr.ParseTreeListener

<file.listenerNames:{lname |
    Enter<lname; format="cap">(*<lname; format="cap">Context)
    Exit<lname; format="cap">(*<lname; format="cap">Context)
}; separator="\n">
}

>>

BaseListenerFile(file, header) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage> // <file.grammarName>
<else>
package parser // <file.grammarName>
<endif>

import "github.com/pboyer/antlr4/runtime/Go/antlr"

// A complete base listener for a parse tree produced by <file.parserName>

type Base<file.grammarName>Listener struct {
}

func (s *Base<file.grammarName>Listener) VisitTerminal(node antlr.TerminalNode){}

func (s *Base<file.grammarName>Listener) VisitErrorNode(node antlr.ErrorNode){}

func (s *Base<file.grammarName>Listener) EnterEveryRule(ctx antlr.ParserRuleContext){}

func (s *Base<file.grammarName>Listener) ExitEveryRule(ctx antlr.ParserRuleContext){}

<file.listenerNames:{lname |

func (s *Base<file.grammarName>Listener) Enter<lname; format="cap">(ctx *<lname; format="cap">Context) {\}

func (s *Base<file.grammarName>Listener) Exit<lname; format="cap">(ctx *<lname; format="cap">Context){\}
}; separator="\n">

>>

VisitorFile(file, header) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage> // <file.grammarName>
<else>
package parser // <file.grammarName>
<endif>

import "github.com/pboyer/antlr4/runtime/Go/antlr"

<header>

// A complete Visitor for a parse tree produced by <file.parserName>.

type <file.grammarName>Visitor interface {
    antlr.ParseTreeVisitor

<file.visitorNames:{lname |
    // Visit a parse tree produced by <file.parserName>#<lname>.
    Visit<lname; format="cap">(ctx *<lname; format="cap">Context) interface{\}
}; separator="\n">
}
>>

BaseVisitorFile(file, header) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage> // <file.grammarName>
<else>
package parser // <file.grammarName>
<endif>

import "github.com/pboyer/antlr4/runtime/Go/antlr"

type Base<file.grammarName>Visitor struct {
    *antlr.BaseParseTreeVisitor
}

<file.visitorNames:{lname |
func (v *Base<file.grammarName>Visitor) Visit<lname; format="cap">(ctx *<lname; format="cap">Context) interface{\} {
    return v.VisitChildren(ctx)
\}}; separator="\n">
>>

Parser(parser, funcs, atn, sempredFuncs, superClass) ::= <<

<if(superClass)>
	import ( "./<superClass>" )
<endif>

var parserATN = <atn>
var deserializer = antlr.NewATNDeserializer(nil)
var deserializedATN = deserializer.DeserializeFromUInt16( parserATN )

var literalNames = []string{ <parser.literalNames:{t | <t>}; null="\"\"", separator=", ", wrap, anchor> }
var symbolicNames = []string{ <parser.symbolicNames:{t | <t>}; null="\"\"", separator=", ", wrap, anchor> }
var ruleNames =  []string{ <parser.ruleNames:{r | "<r>"}; separator=", ", wrap, anchor> }

type <parser.name> struct {
    <superClass; null="*antlr.BaseParser">
}

func New<parser.name>(input antlr.TokenStream) *<parser.name> {

    var decisionToDFA = make([]*antlr.DFA,len(deserializedATN.DecisionToState))
    var sharedContextCache = antlr.NewPredictionContextCache()

    for index, ds := range deserializedATN.DecisionToState {
        decisionToDFA[index] = antlr.NewDFA(ds, index)
    }

    this := new(<parser.name>)

    this.BaseParser = antlr.NewBaseParser(input)

    this.Interpreter = antlr.NewParserATNSimulator(this, deserializedATN, decisionToDFA, sharedContextCache)
    this.RuleNames = ruleNames
    this.LiteralNames = literalNames
    this.SymbolicNames = symbolicNames
    this.GrammarFileName = "<parser.grammarFileName; format="java-escape">"

    return this
}

<namedActions.members>

const(
    <parser.name>EOF = antlr.TokenEOF
    <if(parser.tokens)>
    <parser.tokens:{k | <parser.name><k> = <parser.tokens.(k)>}; separator="\n", wrap, anchor>
    <endif>
)

const (
    <parser.rules:{r | <parser.name>RULE_<r.name> = <r.index>}; separator="\n", wrap, anchor>
)

<funcs; separator="\n">

<if(sempredFuncs)>
func (p *<parser.name>) Sempred(localctx antlr.RuleContext, ruleIndex, predIndex int) bool {
	switch ruleIndex {
	<parser.sempredFuncs.values:{f | case <f.ruleIndex>:
	    var t *<f.name; format="cap">Context = nil
	    if localctx != nil { t = localctx.(*<f.name; format="cap">Context) \}
		return p.<f.name; format="cap">_Sempred(t, predIndex)}; separator="\n">
    default:
        panic("No predicate with index:" + fmt.Sprint(ruleIndex))
   }
}

<sempredFuncs.values; separator="\n">
<endif>

>>

dumpActions(recog, argFuncs, actionFuncs, sempredFuncs) ::= <<
<if(actionFuncs)>
func (l *<lexer.name>) Action(localctx antlr.RuleContext, ruleIndex, actionIndex int) {
	switch ruleIndex {
        <recog.actionFuncs.values:{f|case <f.ruleIndex>:
        <if(!f.isRuleContext)>
        var t *<f.name; format="cap">Context = nil
        if localctx != nil { t = localctx.(*<f.ctxType>) \}
        l.<f.name>_Action(t, actionIndex)
        <else>
        l.<f.name>_Action(localctx, actionIndex)
        <endif>
        break}; separator="\n">
	default:
		panic("No registered action for:" + fmt.Sprint(ruleIndex))
	}
}

<actionFuncs.values; separator="\n">
<endif>
<if(sempredFuncs)>
func (l *<lexer.name>) Sempred(localctx antlr.RuleContext, ruleIndex, predIndex int) bool {
	switch ruleIndex {
		<recog.sempredFuncs.values:{f| case <f.ruleIndex>:
		    <if(!f.isRuleContext)>
            var t *<f.name; format="cap">Context = nil
            if localctx != nil { t = localctx.(*<f.ctxType>) \}
	        return l.<f.name>_Sempred(t, predIndex);
	        <else>
	        return l.<f.name>_Sempred(localctx, predIndex);
	        <endif>}; separator="\n">
    	default:
    		panic("No registered predicate for:" + fmt.Sprint(ruleIndex))
    }
}

<sempredFuncs.values; separator="\n">
<endif>
>>


/* This generates a private method since the actionIndex is generated, making an
 * overriding implementation impossible to maintain.
 */
RuleActionFunction(r, actions) ::= <<

func (l *<lexer.name>) <r.name; format="cap">_Action(localctx <if(r.isRuleContext)>antlr.RuleContext<else>*<r.ctxType><endif>, actionIndex int) {
	switch actionIndex {
	<actions:{index|
case <index>:
	<actions.(index)>
	break}; separator="\n">
	default:
		panic("No registered action for:" + fmt.Sprint(actionIndex))
	}
}
>>

/* This generates a private method since the predIndex is generated, making an
 * overriding implementation impossible to maintain.
 */
RuleSempredFunction(r, actions) ::= <<
func (p *<if(parser)><parser.name><else><lexer.name><endif>) <r.name; format="cap">_Sempred(localctx antlr.RuleContext, predIndex int) bool {
	switch predIndex {
		<actions:{index| case <index>:
	return <actions.(index)>;}; separator="\n">
		default:
			panic("No predicate with index:" + fmt.Sprint(predIndex))
	}
}
>>

RuleFunction(currentRule,args,code,locals,ruleCtx,altLabelCtxs,namedActions,finallyAction,postamble,exceptions) ::= <<

<ruleCtx>

<altLabelCtxs:{l | <altLabelCtxs.(l)>}; separator="\n">

func (p *<parser.name>) <currentRule.name; format="cap">(<currentRule.args:{a | <a.name> <a.type>}; separator=", ">) (localctx I<currentRule.ctxType>) {

    localctx = New<currentRule.ctxType>(p, p.GetParserRuleContext(), p.GetState()<currentRule.args:{a | , <a.name>}>)
    p.EnterRule(localctx, <currentRule.startState>, <parser.name>RULE_<currentRule.name>)
    <namedActions.init>
    <if(locals)>var <locals; separator="\nvar "><endif>

    defer func(){
        <finallyAction>
        p.ExitRule()
    }()

    defer func() {
        if err := recover(); err != nil {
            <if(exceptions)>
            <exceptions; separator="\n">
            <else>
            if v, ok := err.(antlr.RecognitionException); ok {
                localctx.SetException( v )
                p.GetErrorHandler().ReportError(p, v)
                p.GetErrorHandler().Recover(p, v)
            } else {
                panic(err)
            }
            <endif>
        }
    }()

    <code>
    <postamble; separator="\n">
    <namedActions.after>

    return localctx
}

>>

LeftRecursiveRuleFunction(currentRule,args,code,locals,ruleCtx,altLabelCtxs,
	namedActions,finallyAction,postamble) ::=
<<

<ruleCtx>
<altLabelCtxs:{l | <altLabelCtxs.(l)>}; separator="\n">

func (p *<parser.name>) <currentRule.name; format="cap">(_p int<if(currentRule.args)>, <args:{a | , <a.name> <a.type>}><endif>) (localctx I<currentRule.ctxType>) {

    var _parentctx antlr.ParserRuleContext = p.GetParserRuleContext()
    _parentState := p.GetState()
    localctx = New<currentRule.ctxType>(p, p.GetParserRuleContext(), _parentState<args:{a | , <a.name>}>)
    var _prevctx I<currentRule.ctxType> = localctx
    var _ antlr.ParserRuleContext = _prevctx // to prevent unused variable warning
    _startState := <currentRule.startState>
    p.EnterRecursionRule(localctx, <currentRule.startState>, <parser.name>RULE_<currentRule.name>, _p)
    <namedActions.init>
    <if(locals)>var <locals; separator="\nvar "><endif>

    defer func(){
        <finallyAction>
        p.UnrollRecursionContexts(_parentctx)
    }()

    defer func(){
        if err := recover(); err != nil {
            if v, ok := err.(antlr.RecognitionException); ok {
                localctx.SetException(v)
                p.GetErrorHandler().ReportError(p, v)
                p.GetErrorHandler().Recover(p, v)
            } else {
                panic(err)
            }
        }
    }()

    <code>
    <postamble; separator="\n">
    <namedActions.after>

    return localctx
}

>>

CodeBlockForOuterMostAlt(currentOuterMostAltCodeBlock, locals, preamble, ops) ::= <<
<if(currentOuterMostAltCodeBlock.altLabel)>localctx = New<currentOuterMostAltCodeBlock.altLabel; format="cap">Context(p, localctx)<endif>
p.EnterOuterAlt(localctx, <currentOuterMostAltCodeBlock.alt.altNum>)
<CodeBlockForAlt(currentAltCodeBlock=currentOuterMostAltCodeBlock, ...)>
>>

CodeBlockForAlt(currentAltCodeBlock, locals, preamble, ops) ::= <<
<if(locals)>var <locals; separator="\nvar "><endif>
<preamble; separator="\n">
<ops; separator="\n">
>>

LL1AltBlock(choice, preamble, alts, error) ::= <<
p.SetState(<choice.stateNumber>)
<if(choice.label)><labelref(choice.label)> = p.GetTokenStream().LT(1)<endif>
<preamble; separator="\n">
switch p.GetTokenStream().LA(1) {
<choice.altLook,alts:{look,alt| <cases(ttypes=look)>
    <alt>
    break }; separator="\n">
default:
    <error>
}
>>

LL1OptionalBlock(choice, alts, error) ::= <<
p.SetState(<choice.stateNumber>)
switch p.GetTokenStream().LA(1) {
<choice.altLook,alts:{look,alt| <cases(ttypes=look)>
	<alt>
	break }; separator="\n">
default:
	<error>
}
>>

LL1OptionalBlockSingleAlt(choice, expr, alts, preamble, error, followExpr) ::= <<
p.SetState(<choice.stateNumber>)
<preamble; separator="\n">
if <expr> {
    <alts; separator="\n">
}
<!else if ( !(<followExpr>) ) <error>!>
>>

LL1StarBlockSingleAlt(choice, loopExpr, alts, preamble, iteration) ::= <<
p.SetState(<choice.stateNumber>)
p.GetErrorHandler().Sync(p)
<preamble; separator="\n">
for <loopExpr> {
    <alts; separator="\n">
    p.SetState(<choice.loopBackStateNumber>)
    p.GetErrorHandler().Sync(p)
    <iteration>
}
>>

LL1PlusBlockSingleAlt(choice, loopExpr, alts, preamble, iteration) ::= <<
p.SetState(<choice.blockStartStateNumber>) <! alt block decision !>
p.GetErrorHandler().Sync(p)
<preamble; separator="\n">
for ok := true; ok; ok = <loopExpr> {
    <alts; separator="\n">
    p.SetState(<choice.stateNumber>); <! loopback/exit decision !>
    p.GetErrorHandler().Sync(p)
    <iteration>
}
>>

// LL(*) stuff

AltBlock(choice, preamble, alts, error) ::= <<
p.SetState(<choice.stateNumber>)
p.GetErrorHandler().Sync(p)
<if(choice.label)><labelref(choice.label)> = _input.LT(1)<endif>
<preamble; separator="\n">
la_ := p.GetInterpreter().AdaptivePredict(p.GetTokenStream(),<choice.decision>,p.GetParserRuleContext())
switch la_ {
<alts:{alt |
case <i>:
    <alt>
    break
}; separator="\n">
}
>>

OptionalBlock(choice, alts, error) ::= <<
p.SetState(<choice.stateNumber>)
p.GetErrorHandler().Sync(p)
la_ := p.GetInterpreter().AdaptivePredict(p.GetTokenStream(),<choice.decision>,p.GetParserRuleContext())
<alts:{alt |
if la_==<i><if(!choice.ast.greedy)>+1<endif> {
    <alt>
}; separator="} else ">
}
>>

StarBlock(choice, alts, Sync, iteration) ::= <<
p.SetState(<choice.stateNumber>)
p.GetErrorHandler().Sync(p)
_alt := p.GetInterpreter().AdaptivePredict(p.GetTokenStream(),<choice.decision>,p.GetParserRuleContext())
for _alt!=<choice.exitAlt> && _alt!= antlr.ATNInvalidAltNumber {
    if(_alt==1<if(!choice.ast.greedy)>+1<endif>) {
        <iteration>
        <alts> <! should only be one !>
    }
    p.SetState(<choice.loopBackStateNumber>)
    p.GetErrorHandler().Sync(p)
    _alt = p.GetInterpreter().AdaptivePredict(p.GetTokenStream(),<choice.decision>,p.GetParserRuleContext())
}

>>

PlusBlock(choice, alts, error) ::= <<
p.SetState(<choice.blockStartStateNumber>) <! alt block decision !>
p.GetErrorHandler().Sync(p)
_alt := 1<if(!choice.ast.greedy)>+1<endif>
for ok := true; ok; ok = _alt!=<choice.exitAlt> && _alt!= antlr.ATNInvalidAltNumber {
	switch _alt {
	<alts:{alt|
case <i><if(!choice.ast.greedy)>+1<endif>:
	<alt>
	break }; separator="\n">
	default:
		<error>
	}
	p.SetState(<choice.loopBackStateNumber>) <! loopback/exit decision !>
	p.GetErrorHandler().Sync(p)
	_alt = p.GetInterpreter().AdaptivePredict(p.GetTokenStream(),<choice.decision>, p.GetParserRuleContext())
}
>>

Sync(s) ::= "Sync(<s.expecting.name>)"

ThrowNoViableAlt(t) ::= "panic(antlr.NewNoViableAltException(p, nil, nil, nil, nil, nil))"

TestSetInline(s) ::= <<
<s.bitsets:{bits | <if(rest(rest(bits.ttypes)))><bitsetBitfieldComparison(s, bits)><else><bitsetInlineComparison(s, bits)><endif>}; separator=" || ">
>>

// Javascript language spec - shift operators are 32 bits long max
testShiftInRange(shiftAmount) ::= <<
((<shiftAmount>) & -(0x1f+1)) == 0
>>

// produces smaller bytecode only when bits.ttypes contains more than two items
bitsetBitfieldComparison(s, bits) ::= <%
(<testShiftInRange({<offsetShiftVar(s.varName, bits.shift)>})> && ((1 \<\< uint(<offsetShiftVar(s.varName, bits.shift)>)) & (<bits.ttypes:{ttype | (1 \<\< <offsetShiftType(ttype, bits.shift)>)}; separator=" | ">)) != 0)
%>

isZero ::= [
"0":true,
default:false
]

offsetShiftVar(shiftAmount, offset) ::= <%
<if(!isZero.(offset))>(<shiftAmount> - <offset>)<else><shiftAmount><endif>
%>

offsetShiftType(shiftAmount, offset) ::= <%
<if(!isZero.(offset))>(<parser.name><shiftAmount> - <offset>)<else><parser.name><shiftAmount><endif>
%>

// produces more efficient bytecode when bits.ttypes contains at most two items
bitsetInlineComparison(s, bits) ::= <%
<bits.ttypes:{ttype | <s.varName>==<parser.name><ttype>}; separator=" || ">
%>

cases(ttypes) ::= <<
<ttypes:{t | case <parser.name><t>:}; separator="fallthrough \n">
>>

InvokeRule(r, argExprsChunks) ::= <<
p.SetState(<r.stateNumber>)
<if(r.labels)><r.labels:{l | <labelref(l)> = }><endif>p.<r.name; format="cap">(<if(r.ast.options.p)><r.ast.options.p><if(argExprsChunks)>,<endif><endif><argExprsChunks>)
>>

MatchToken(m) ::= <<
p.SetState(<m.stateNumber>)
<if(m.labels)><m.labels:{l | <labelref(l)> = }><endif>p.Match(<parser.name><m.name>)
>>

MatchSet(m, expr, capture) ::= "<CommonSetStuff(m, expr, capture, false)>"

MatchNotSet(m, expr, capture) ::= "<CommonSetStuff(m, expr, capture, true)>"

CommonSetStuff(m, expr, capture, invert) ::= <<
p.SetState(<m.stateNumber>)
<if(m.labels)><m.labels:{l | <labelref(l)> = }>p.GetTokenStream().LT(1);<endif>
<capture>
<if(invert)>if <m.varName>\<=0 || <expr> <else>if !(<expr>)<endif> {
    <if(m.labels)><m.labels:{l | <labelref(l)> = }><endif>p.GetErrorHandler().RecoverInline(p)
} else {
    p.Consume()
}
>>

Wildcard(w) ::= <<
p.SetState(<w.stateNumber>)
<if(w.labels)><w.labels:{l | <labelref(l)> = }><endif>p.MatchWildcard()
>>

// ACTION STUFF

Action(a, foo, chunks) ::= "<chunks>"

ArgAction(a, chunks) ::= "<chunks>"

SemPred(p, chunks, failChunks) ::= <<
p.SetState(<p.stateNumber>)
if !( <chunks>) {
    panic( antlr.NewFailedPredicateException(p, <p.predicate><if(failChunks)>, <failChunks><elseif(p.msg)>, <p.msg><else>, ""<endif>))
}
>>

ExceptionClause(e, catchArg, catchAction) ::= <<
catch (<catchArg>) {
	<catchAction>
}
>>

// lexer actions are not associated with model objects

LexerSkipCommand()  ::= "p.Skip()"
LexerMoreCommand()  ::= "p.More()"
LexerPopModeCommand() ::= "p.PopMode()"
LexerTypeCommand(arg)      ::= "p.SetType(<arg>)"
LexerChannelCommand(arg)   ::= "p.SetChannel(<arg>)"
LexerModeCommand(arg)      ::= "p.SetMode(<arg>)"
LexerPushModeCommand(arg)  ::= "p.PushMode(<arg>)"

ActionText(t) ::= "<t.text>"
ActionTemplate(t) ::= "<t.st>"

ArgRef(a) ::= "<ctx(a)>.<a.name>"
LocalRef(a) ::= "<ctx(a)>.<a.name>"
RetValueRef(a) ::= "<ctx(a)>.<a.name>"
QRetValueRef(a) ::= "<ctx(a)>.Get<a.dict;format={cap}>().Get<a.name;format={cap}>()"

/** How to translate $tokenLabel */
TokenRef(t) ::= "<ctx(t)>.Get<t.name;format={cap}>()"
LabelRef(t) ::= "<ctx(t)>.Get<t.name;format={cap}>()"
ListLabelRef(t) ::= "<ctx(t)>.Get<ListLabelName(t.name);format={cap}>"

SetAttr(s,rhsChunks) ::= "<ctx(s)>.Set<s.name; format={cap}>(<rhsChunks>)"

TokenLabelType() ::= "<file.TokenLabelType; null={antlr.Token}>"
InputSymbolType() ::= "<file.InputSymbolType; null={antlr.Token}>"

TokenPropertyRef_text(t) ::= "(func() string { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return \"\" } else { return <ctx(t)>.Get<t.label; format={cap}>().GetText() }}())"
TokenPropertyRef_type(t) ::=  "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { return <ctx(t)>.Get<t.label; format={cap}>().GetTokenType() }}())"
TokenPropertyRef_line(t) ::= "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { return <ctx(t)>.Get<t.label; format={cap}>().GetLine() }}())"
TokenPropertyRef_pos(t) ::= "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { return <ctx(t)>.Get<t.label; format={cap}>().GetColumn() }}())"
TokenPropertyRef_channel(t) ::= "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { return <ctx(t)>.Get<t.label; format={cap}>().GetChannel() }}())"
TokenPropertyRef_index(t) ::= "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { return <ctx(t)>.Get<t.label; format={cap}>().GetTokenIndex() }}())"
TokenPropertyRef_int(t) ::= "(func() int { if <ctx(t)>.Get<t.label; format={cap}>() == nil { return 0 } else { i,_ := strconv.Atoi(<ctx(t)>.Get<t.label; format={cap}>().GetText()); return i }}())"

RulePropertyRef_start(r) ::= "(func() antlr.Token { if <ctx(r)>.Get<r.label;format={cap}>() == nil { return nil } else { return <ctx(r)>.Get<r.label;format={cap}>().GetStart() }}())"
RulePropertyRef_stop(r)	 ::= "(func() antlr.Token { if <ctx(r)>.Get<r.label;format={cap}>() == nil { return nil } else { return <ctx(r)>.Get<r.label;format={cap}>().GetStop() }}())"
RulePropertyRef_text(r)	 ::= "(func() string { if <ctx(r)>.Get<r.label;format={cap}>() == nil { return \"\" } else { return p.GetTokenStream().GetTextFromTokens( <ctx(r)>.Get<r.label;format={cap}>().GetStart(),<ctx(r)>.<r.label>.GetStop()) }}())"
RulePropertyRef_ctx(r)	 ::= "<ctx(r)>.Get<r.label;format={cap}>()"
RulePropertyRef_parser(r)	 ::= "p"

ThisRulePropertyRef_start(r) ::= "localctx.GetStart()"
ThisRulePropertyRef_stop(r)	 ::= "localctx.GetStop()"
ThisRulePropertyRef_text(r)	 ::= "p.GetTokenStream().GetTextFromTokens(localctx.GetStart(), p.GetTokenStream().LT(-1))"
ThisRulePropertyRef_ctx(r)	 ::= "<ctx(r)>"
ThisRulePropertyRef_parser(r)	 ::= "p"

NonLocalAttrRef(s)		 	 ::= "GetInvokingContext(<s.ruleIndex>).<s.name>"
SetNonLocalAttr(s, rhsChunks)  ::= "GetInvokingContext(<s.ruleIndex>).<s.name> = <rhsChunks>"

AddToLabelList(a) ::= "<ctx(a.label)>.<a.listName> = append(<ctx(a.label)>.<a.listName>, <labelref(a.label)>)"

TokenDecl(t) ::= "<t.name> <TokenLabelType()>"
TokenTypeDecl(t) ::= "<t.name> int"
TokenListDecl(t) ::= "<t.name> []antlr.Token"

RuleContextDecl(r) ::= "<r.name> I<r.ctxName>"
RuleContextListDecl(rdecl) ::= "<rdecl.name> []I<rdecl.ctxName>"

AttributeDecl(d) ::= "<d.name> <d.type;format={lower}><if(d.initValue)>// TODO = <d.initValue><endif>"

ContextTokenGetterDecl(t)      ::= <<
<t.name; format="cap">() antlr.TerminalNode {
    return s.GetToken(<parser.name><t.name>, 0)
}
>>

// should never be called
ContextTokenListGetterDecl(t)  ::= <<
fail: ContextTokenListGetterDecl should never be called!
>>

ContextTokenListIndexedGetterDecl(t)  ::= <<
<t.name; format="cap">(i int) []antlr.TerminalNode {
    if i \< 0 {
        return s.GetTokens(<parser.name><t.name>)
    } else {
        return []antlr.TerminalNode{ s.GetToken(<parser.name><t.name>, i) }
    }
}
>>

ContextRuleGetterDecl(r)       ::= <<
<r.name; format="cap">() I<r.ctxName> {
    v := s.GetTypedRuleContext( reflect.TypeOf((*I<r.ctxName>)(nil)).Elem(),0);

    if v == nil {
        return nil
    }

    return v.(I<r.ctxName>)
}
>>

// should never be called
ContextRuleListGetterDecl(r)   ::= <<
fail: ContextRuleListGetterDecl should never be called!
>>

ContextRuleListIndexedGetterDecl(r)   ::= <<
<r.name; format="cap">(i int) []I<r.ctxName> {
    var ts []antlr.RuleContext;

    if i \< 0 {
        ts = s.GetTypedRuleContexts( reflect.TypeOf((*I<r.ctxName>)(nil)).Elem())
    } else {
        ts = []antlr.RuleContext { s.GetTypedRuleContext( reflect.TypeOf((*I<r.ctxName>)(nil)).Elem(),i) }
    }

    var tst []I<r.ctxName> = make([]I<r.ctxName>, len(ts))
    for i, t := range ts {
        if t == nil {
            tst[i] = nil
        } else {
            tst[i] = t.(I<r.ctxName>)
        }
    }

    return tst
}
>>

LexerRuleContext() ::= "RuleContext"

/** The rule context name is the rule followed by a suffix; e.g.,
 *	r becomes rContext.
 */
RuleContextNameSuffix() ::= "Context"

ImplicitTokenLabel(tokenName) ::= "_<tokenName>"
ImplicitRuleLabel(ruleName)	  ::= "_<ruleName>"
ImplicitSetLabel(id)		  ::= "_tset<id>"
ListLabelName(label)		  ::= "<label>"

CaptureNextToken(d) ::= "<d.varName> = p.GetTokenStream().LT(1)"
CaptureNextTokenType(d) ::= "<d.varName> = p.GetTokenStream().LA(1);"

StructDecl(struct,ctorAttrs,attrs,getters,dispatchMethods,interfaces,extensionMembers,tokenDecls,tokenTypeDecls,
    tokenListDecls,ruleContextDecls,ruleContextListDecls,attributeDecls,superClass={ParserRuleContext}) ::= <<

// an interface to support dynamic dispatch (subclassing)

type I<struct.name> interface {
    antlr.ParserRuleContext

    GetParser() antlr.Parser
    get<struct.name>() // to differentiate from other interfaces

    <struct.tokenDecls:{a | Get<a.name; format="cap">() <TokenLabelType()> }; separator="\n">
    <struct.tokenDecls:{a | Set<a.name; format="cap">(<TokenLabelType()>) }; separator="\n">
    <struct.tokenTypeDecls:{a | Get<a.name; format="cap">() int }; separator="\n">
    <struct.tokenTypeDecls:{a | Set<a.name; format="cap">(int) }; separator="\n">
    <struct.tokenListDecls:{a | Get<a.name; format="cap">() []<TokenLabelType()>}; separator="\n">
    <struct.tokenListDecls:{a | Set<a.name; format="cap">([]<TokenLabelType()>)}; separator="\n">
    <struct.ruleContextDecls:{a | Get<a.name; format="cap">() I<a.ctxName>}; separator="\n">
    <struct.ruleContextDecls:{a | Set<a.name; format="cap">(I<a.ctxName>)}; separator="\n">
    <struct.ruleContextListDecls:{a | Get<a.name; format="cap">() []I<a.ctxName>}; separator="\n">
    <struct.ruleContextListDecls:{a | Set<a.name; format="cap">([]I<a.ctxName>) }; separator="\n">
    <struct.attributeDecls:{a | Get<a.name; format="cap">() <a.type;format="lower">}; separator="\n">
    <struct.attributeDecls:{a | Set<a.name; format="cap">(<a.type;format="lower">)}; separator="\n">
}

type <struct.name> struct {
    *antlr.BaseParserRuleContext

    parser antlr.Parser
    <attrs:{a | <a>}; separator="\n">
}

func NewEmpty<struct.name>() *<struct.name> {
    var p = new(<struct.name>)
    p.BaseParserRuleContext = antlr.NewBaseParserRuleContext( nil, -1 )
    p.RuleIndex = <parser.name>RULE_<struct.derivedFromName>
    return p
}

func (*<struct.name>) get<struct.name>() {}

func New<struct.name>(parser antlr.Parser, parent antlr.ParserRuleContext, invokingState int<struct.ctorAttrs:{a | , <a.name> <a.type;format="lower">}>) *<struct.name> {

    var p = new(<struct.name>)

    p.BaseParserRuleContext = antlr.NewBaseParserRuleContext( parent, invokingState )

    p.parser = parser
    p.RuleIndex = <parser.name>RULE_<struct.derivedFromName>

    <struct.ctorAttrs:{a | p.<a.name> = <a.name>}; separator="\n">
    return p
}

func (s *<struct.name>) GetParser() antlr.Parser { return s.parser }

<struct.tokenDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() <TokenLabelType()> { return s.<a.name> \} }; separator="\n">
<struct.tokenDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v <TokenLabelType()>) { s.<a.name> = v \} }; separator="\n">
<struct.tokenTypeDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() int { return s.<a.name> \}  }; separator="\n">
<struct.tokenTypeDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v int) { s.<a.name> = v \} }; separator="\n">
<struct.tokenListDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() []<TokenLabelType()>  { return s.<a.name> \} }; separator="\n">
<struct.tokenListDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v []<TokenLabelType()>) { s.<a.name> = v \}}; separator="\n">
<struct.ruleContextDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() I<a.ctxName>  { return s.<a.name> \} }; separator="\n">
<struct.ruleContextDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v I<a.ctxName>) { s.<a.name> = v \}}; separator="\n">
<struct.ruleContextListDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() []I<a.ctxName>  { return s.<a.name> \} }; separator="\n">
<struct.ruleContextListDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v []I<a.ctxName>) { s.<a.name> = v \} }; separator="\n">
<struct.attributeDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() <a.type;format="lower">  { return s.<a.name> \} }; separator="\n">
<struct.attributeDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v <a.type;format="lower">) { s.<a.name> = v \}}; separator="\n">

<getters:{g | func (s *<struct.name>) <g>}; separator="\n\n">

<if(struct.provideCopyFrom)> <! don't need unless we have subclasses !>

func (s *<struct.name>) CopyFrom(ctx *<struct.name>) {
    s.BaseParserRuleContext.CopyFrom(ctx.BaseParserRuleContext)
    <struct.attrs:{a | s.<a.name> = ctx.<a.name>;}; separator="\n">
}
<endif>

func (s *<struct.name>) GetRuleContext() antlr.RuleContext { return s }

<dispatchMethods; separator="\n">
<extensionMembers; separator="\n">

>>

AltLabelStructDecl(struct,attrs,getters,dispatchMethods,tokenDecls,tokenTypeDecls,
  tokenListDecls,ruleContextDecls,ruleContextListDecls,attributeDecls) ::= <<

type <struct.name> struct {
    *<currentRule.name; format="cap">Context

    <attrs:{a | <a>}; separator="\n">
}

func New<struct.name>(parser antlr.Parser, ctx antlr.ParserRuleContext) *<struct.name> {

    var p = new(<struct.name>)

    p.<currentRule.name; format="cap">Context = NewEmpty<currentRule.name; format="cap">Context()
    p.parser = parser
    p.CopyFrom(ctx.(*<currentRule.name; format="cap">Context))

    return p
}

<struct.tokenDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() <TokenLabelType()> { return s.<a.name> \} }; separator="\n">
<struct.tokenDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v <TokenLabelType()>) { s.<a.name> = v \} }; separator="\n">
<struct.tokenTypeDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() int { return s.<a.name> \}  }; separator="\n">
<struct.tokenTypeDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v int) { s.<a.name> = v \} }; separator="\n">
<struct.tokenListDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() []<TokenLabelType()>  { return s.<a.name> \} }; separator="\n">
<struct.tokenListDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v []<TokenLabelType()>) { s.<a.name> = v \}}; separator="\n">
<struct.ruleContextDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() I<a.ctxName>  { return s.<a.name> \} }; separator="\n">
<struct.ruleContextDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v I<a.ctxName>) { s.<a.name> = v \}}; separator="\n">
<struct.ruleContextListDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() []I<a.ctxName>  { return s.<a.name> \} }; separator="\n">
<struct.ruleContextListDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v []I<a.ctxName>) { s.<a.name> = v \} }; separator="\n">
<struct.attributeDecls:{a | func (s *<struct.name>) Get<a.name; format="cap">() <a.type;format="lower">  { return s.<a.name> \} }; separator="\n">
<struct.attributeDecls:{a | func (s *<struct.name>) Set<a.name; format="cap">(v <a.type;format="lower">) { s.<a.name> = v \}}; separator="\n">

func (s *<struct.name>) GetRuleContext() antlr.RuleContext { return s }

<getters:{g | func (s *<struct.name>) <g>}; separator="\n\n">
<dispatchMethods; separator="\n">

>>

ListenerDispatchMethod(method) ::= <<
func (s *<struct.name>) <if(method.isEnter)>Enter<else>Exit<endif>Rule(listener antlr.ParseTreeListener) {
    if listenerT, ok := listener.(<parser.grammarName>Listener); ok {
        listenerT.<if(method.isEnter)>Enter<else>Exit<endif><struct.derivedFromName; format="cap">(s)
    }
}
>>

VisitorDispatchMethod(method) ::= <<
func (s *<struct.name>) Accept(visitor antlr.ParseTreeVisitor) interface{} {
    switch t := visitor.(type) {
    case <parser.grammarName>Visitor:
        return t.Visit<struct.derivedFromName; format="cap">(s)
    default:
        return t.VisitChildren(s)
    }
}
>>


/** If we don't know location of label def x, use this template */
labelref(x) ::= "<if(!x.isLocal)>localctx.(*<x.ctx.name>).<endif><x.name>"

/** For any action chunk, what is correctly-typed context struct ptr? */
ctx(actionChunk) ::= "localctx.(*<actionChunk.ctx.name>)"

// used for left-recursive rules
recRuleAltPredicate(ruleName,opPrec)  ::= "p.Precpred(p.GetParserRuleContext(), <opPrec>)"
recRuleSetReturnAction(src,name)	  ::= "$<name>=$<src>.<name>"
recRuleSetStopToken()                 ::= "p.GetParserRuleContext().SetStop( p.GetTokenStream().LT(-1) )"

recRuleAltStartAction(ruleName, ctxName, label) ::= <<
localctx = New<ctxName>Context(p, _parentctx, _parentState)
<if(label)>localctx.(*<ctxName>Context).<label> = _prevctx<endif>
p.PushNewRecursionContext(localctx, _startState, <parser.name>RULE_<ruleName>)
>>

recRuleLabeledAltStartAction(ruleName, currentAltLabel, label, isListLabel) ::= <<
localctx = New<currentAltLabel; format="cap">Context(p, New<ruleName; format="cap">Context(p, _parentctx, _parentState))
<if(label)>
<if(isListLabel)>
localctx.(*<currentAltLabel; format="cap">Context).<label> = append( localctx.(*<currentAltLabel; format="cap">Context).<label>, _prevctx)
<else>
localctx.(*<currentAltLabel; format="cap">Context).<label> = _prevctx
<endif>
<endif>
p.PushNewRecursionContext(localctx, _startState, <parser.name>RULE_<ruleName>)
>>

recRuleReplaceContext(ctxName) ::= <<
localctx = New<ctxName>Context(p, localctx)
p.SetParserRuleContext(localctx)
_prevctx = localctx
>>

recRuleSetPrevCtx() ::= <<
if p.GetParseListeners()!=nil {
    p.TriggerExitRuleEvent()
}
_prevctx = localctx
>>


LexerFile(file, lexer, namedActions) ::= <<
<fileHeader(file.grammarFileName, file.ANTLRVersion)>
<if(file.genPackage)>
package <file.genPackage><! // <file.grammarName>!><! why can't we access file.grammarName here? !>
<else>
package parser<! // <file.grammarName>!><! why can't we access file.grammarName here? !>
<endif>

import (
    "fmt"

    "github.com/pboyer/antlr4/runtime/Go/antlr"
)

// suppress unused import error, many tests
// require fmt.
var _ = fmt.Printf

<namedActions.header>

<lexer>

>>

Lexer(lexer, atn, actionFuncs, sempredFuncs, superClass) ::= <<

var serializedLexerAtn = <atn>
var lexerDeserializer = antlr.NewATNDeserializer(nil)
var lexerAtn = lexerDeserializer.DeserializeFromUInt16( serializedLexerAtn )

var lexerModeNames = []string{ <lexer.modes:{m| "<m>"}; separator=", ", wrap, anchor> }
var lexerLiteralNames = []string{ <lexer.literalNames:{t | <t>}; null="\"\"", separator=", ", wrap, anchor> }
var lexerSymbolicNames = []string{ <lexer.symbolicNames:{t | <t>}; null="\"\"", separator=", ", wrap, anchor> }
var lexerRuleNames = []string{ <lexer.ruleNames:{r | "<r>"}; separator=", ", wrap, anchor> }

type <lexer.name> struct {
    *<if(superClass)><superClass><else>antlr.BaseLexer<endif>

    modeNames []string
    // EOF string
}

func New<lexer.name>(input antlr.CharStream) *<lexer.name> {

    var lexerDecisionToDFA = make([]*antlr.DFA,len(lexerAtn.DecisionToState))

    for index, ds := range lexerAtn.DecisionToState {
        lexerDecisionToDFA[index] = antlr.NewDFA(ds, index)
    }

	this := new(<lexer.name>)

	this.BaseLexer = antlr.NewBaseLexer(input)

    this.Interpreter = antlr.NewLexerATNSimulator(this, lexerAtn, lexerDecisionToDFA, antlr.NewPredictionContextCache())

    this.modeNames = lexerModeNames
    this.RuleNames = lexerRuleNames
    this.LiteralNames = lexerLiteralNames
    this.SymbolicNames = lexerSymbolicNames
    this.GrammarFileName = "<lexer.grammarFileName>"
    //lex.EOF = antlr.TokenEOF

    return this
}

const (
    <lexer.tokens:{k | <lexer.name><k> = <lexer.tokens.(k)>}; separator="\n", wrap, anchor>
)

const (
    <rest(lexer.modes):{m| <lexer.name><m> = <i>}; separator="\n">
)


<dumpActions(lexer, "", actionFuncs, sempredFuncs)>

>>

SerializedATN(model) ::= <<
<! only one segment, can be inlined !>
[]uint16{ <model.serialized; wrap={<\n>    }> }

>>

/**
 * Using a type to init value map, try to init a type; if not in table
 *	must be an object, default value is "nil".
 */
initValue(typeName) ::= <<
<javaTypeInitMap.(typeName)>
>>

RecognizerFileName(name,type) ::= "<name; format={lower}>_<type; format={lower}>"
ListenerFileName(name) ::= "<name; format={lower}>_listener"
VisitorFileName(name) ::= "<name; format={lower}>_visitor"
BaseListenerFileName(name) ::= "<name; format={lower}>_base_listener"
BaseVisitorFileName(name) ::= "<name; format={lower}>_base_visitor"

codeFileExtension() ::= ".go"
